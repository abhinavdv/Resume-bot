{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UniqueConstraintError",
     "evalue": "Collection resume_data already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUniqueConstraintError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m collection \u001b[38;5;241m=\u001b[39m \u001b[43mchroma_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresume_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/Resume-bot/.venv/lib/python3.11/site-packages/chromadb/api/client.py:147\u001b[0m, in \u001b[0;36mClient.create_collection\u001b[0;34m(self, name, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_collection\u001b[39m(\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    145\u001b[0m     get_or_create: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    146\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Collection:\n\u001b[0;32m--> 147\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[1;32m    156\u001b[0m         client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server,\n\u001b[1;32m    157\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    158\u001b[0m         embedding_function\u001b[38;5;241m=\u001b[39membedding_function,\n\u001b[1;32m    159\u001b[0m         data_loader\u001b[38;5;241m=\u001b[39mdata_loader,\n\u001b[1;32m    160\u001b[0m     )\n",
      "File \u001b[0;32m~/Code/Resume-bot/.venv/lib/python3.11/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Code/Resume-bot/.venv/lib/python3.11/site-packages/chromadb/api/segment.py:103\u001b[0m, in \u001b[0;36mrate_limit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rate_limit_enforcer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrate_limit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/Resume-bot/.venv/lib/python3.11/site-packages/chromadb/rate_limit/simple_rate_limit/__init__.py:24\u001b[0m, in \u001b[0;36mSimpleRateLimitEnforcer.rate_limit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/Resume-bot/.venv/lib/python3.11/site-packages/chromadb/api/segment.py:242\u001b[0m, in \u001b[0;36mSegmentAPI.create_collection\u001b[0;34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    229\u001b[0m model \u001b[38;5;241m=\u001b[39m CollectionModel(\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[1;32m    231\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m     dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    239\u001b[0m )\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# TODO: Let sysdb create the collection directly from the model\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m coll, created \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sysdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43msegments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Passing empty till backend changes are deployed.\u001b[39;49;00m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# This is lazily populated on the first add\u001b[39;49;00m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created:\n\u001b[1;32m    255\u001b[0m     segments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mprepare_segments_for_new_collection(coll)\n",
      "File \u001b[0;32m~/Code/Resume-bot/.venv/lib/python3.11/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Code/Resume-bot/.venv/lib/python3.11/site-packages/chromadb/db/mixins/sysdb.py:305\u001b[0m, in \u001b[0;36mSqlSysDB.create_collection\u001b[0;34m(self, id, name, configuration, segments, metadata, dimension, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_collections(\n\u001b[1;32m    300\u001b[0m                 \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mcollection\u001b[38;5;241m.\u001b[39mid, tenant\u001b[38;5;241m=\u001b[39mtenant, database\u001b[38;5;241m=\u001b[39mdatabase\n\u001b[1;32m    301\u001b[0m             )[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    302\u001b[0m             \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    303\u001b[0m         )\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 305\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UniqueConstraintError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    307\u001b[0m collection \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[1;32m    309\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    316\u001b[0m )\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtx() \u001b[38;5;28;01mas\u001b[39;00m cur:\n",
      "\u001b[0;31mUniqueConstraintError\u001b[0m: Collection resume_data already exists"
     ]
    }
   ],
   "source": [
    "collection = chroma_client.create_collection(name=\"resume_data\", )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insert of existing embedding ID: doc_0\n",
      "Add of existing embedding ID: doc_0\n"
     ]
    }
   ],
   "source": [
    "# Read and add documents to ChromaDB\n",
    "import os\n",
    "\n",
    "# Example: reading text files from a directory\n",
    "documents = []\n",
    "metadatas = []\n",
    "ids = []\n",
    "\n",
    "doc_dir = \"docs\"\n",
    "for i, filename in enumerate(os.listdir(doc_dir)):\n",
    "    if filename.endswith(\".txt\"):  # or any other extension you're using\n",
    "        with open(os.path.join(doc_dir, filename), 'r') as file:\n",
    "            content = file.read()\n",
    "            documents.append(content)\n",
    "            metadatas.append({\"source\": filename})\n",
    "            ids.append(f\"doc_{i}\")\n",
    "\n",
    "# Add documents to the collection\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keys\n",
    "OPENAI_API_KEY = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you with information about Abhinav Duvvuri's resume today?None"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = OPENAI_API_KEY)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are an assistant who talks about Abhinav Duvvuri's resume. NEVER ANSWER ANYTHING OUTSIDE THE CONTEXT. NEVER EVER\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ],\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "  print(chunk.choices[0].delta.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_context(query, k=3):\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=k\n",
    "    )\n",
    "    # Combine the retrieved documents into a single context string\n",
    "    context = \"\\n\\n\".join(results['documents'][0])\n",
    "    return context\n",
    "\n",
    "# Example chat with context\n",
    "query = \"Tell me about Abhinav's experience\"\n",
    "context = get_relevant_context(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abhinav is skilled with the following tech stack:\n",
      "\n",
      "- Tools: Object Oriented (OOP) Python, SQL, Semantic Kernel, C#, Azure, Azure AI, Service-Now, Kubernetes, Docker\n",
      "- Experience: RAG implementations, GenAI Agentic Frameworks, Fast API, scalable REST APIs, LLM prompt Engineering, performance tuningNone"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! If you have any questions about Abhinav Duvvuri's resume, feel free to ask, and I'll do my best to provide the information based on the context given.None"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I assist you with Abhinav Duvvuri's resume?None"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I assist you regarding Abhinav Duvvuri's resume?None"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Example chat with context\n",
    "    query = input(\"What do you want to know about Abhinav: \")\n",
    "    context = get_relevant_context(query)\n",
    "    if query.lower() == \"bye\":\n",
    "        print('Have a lovely day!')\n",
    "        break\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant who talks about Abhinav Duvvuri's resume. Only use the provided context to answer questions. If you can't find the information in the context, say you don't have that information.\"},\n",
    "            {\"role\": \"system\", \"content\": f\"Context from resume: {context}\"},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    for chunk in completion:\n",
    "        print(chunk.choices[0].delta.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"Hello!  I\\'m ready to answer your questions based on your resume. Please ask away.\\n\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  grounding_metadata {\n",
      "    retrieval_metadata {\n",
      "    }\n",
      "  }\n",
      "  avg_logprobs: -0.058454297837756929\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 43\n",
      "  candidates_token_count: 21\n",
      "  total_token_count: 64\n",
      "}\n",
      "model_version: \"gemini-1.5-flash-002\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"Based on the provided resume, Abhinav Duvvuri excels in several areas:\\n\\n* **AI Engineering and Development:** He has extensive experience in developing and implementing enterprise-level AI solutions, including RAG implementations, GenAI Agentic Frameworks, and LLM prompt engineering.  He\\'s proficient in using various tools and technologies like Azure AI, OpenAI APIs, Semantic Kernel, and MongoDB.  His projects demonstrate expertise in building AI copilots,  creating reusable AI libraries, and integrating AI into existing infrastructure.\\n\\n* **Software Development:** Abhinav possesses strong software development skills, with experience in building scalable REST APIs, using languages like Python and C#, and frameworks like FastAPI. He\\'s also familiar with containerization technologies like Docker and Kubernetes.  His experience includes working with ServiceNow to optimize digital portfolios.\\n\\n* **Data Science:** His Master\\'s degree in Data Science and coursework demonstrate a solid foundation in machine learning, data structures and algorithms, statistics, and data visualization.  He has experience with ensemble methods, predictive modeling, and working with large datasets.  His research on solar power generation showcases his analytical and problem-solving abilities.\\n\\n* **Technical Leadership and Teamwork:** Abhinav has led technical teams, provided guidance on implementation and design, and mentored junior team members. He demonstrates strong stakeholder management skills and the ability to collaborate effectively.\\n\\n* **Adaptability and Learning:** He is described as a highly adaptable and quick learner, able to independently start projects and successfully navigate new technologies and challenges.\\n\\n\\nHe is also a strong researcher and actively promotes the latest advancements in AI within his organizations.\\n\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  grounding_metadata {\n",
      "    retrieval_queries: \"what is abhinav good at\"\n",
      "    grounding_chunks {\n",
      "      retrieved_context {\n",
      "        uri: \"gs://resume-data-abh/resume_AD_AI_CD.docx.txt\"\n",
      "        title: \"resume_AD_AI_CD.docx\"\n",
      "        text: \"Tech in Computer Science with Distinction\\r\\n    Coursework: Machine Learning, Data Structures and Algorithms, Software development, Database management systems\\r\\nTECHNICAL SKILLS\\r\\n  Tools:                                          Object Oriented(OOP) Python, SQL, Semantic Kernel, C#, Azure, Azure AI, Service-Now, Kubernetes, Docker\\r\\n  Experience:                         RAG implementations, GenAI Agentic Frameworks, Fast API, scalable REST APIs, LLM prompt Engineering, performance tuning\\r\\n  Interpersonal Skills:            Highly adaptable, Quick Learner, Independent Starter, good stakeholder management skills. AWARDS * Won the Rising Star award in the architecture pillar of SLB for the year 2022-23 * Check https://www.linkedin.com/in/abhinav-duvvuri/details/recommendations/ for recommendations. RELATED PROJECTS AND RESEARCH PAPERS\\r\\n  Conversational AI Co-Pilot, SLB        July 2024 - Present (Ongoing) * Developed an enterprise-level AI copilot, facilitating seamless interaction and management of digital portfolios. * Created reusable AI libraries to streamline AI solution implementation for other teams. * Utilized the agentic framework for precise query classification and contextual understanding, improving user experience and decreasing support workload through intelligent multi-prompts and a RAG-based approach. * Leveraged semantic kernel SDK for AI orchestration, enabling MongoDB database queries and API calls for real-time data summarization and retrieval. Ensemble Based Predictive Model for Streaming Data \\n...\\n﻿Abhinav Duvvuri\\r\\nSeattle, WA 98105\\r\\nPhone: 4255425032 ⋄ Email: dvabhinav31@gmail.com\\r\\nWORK EXPERIENCE\\r\\n Capstone Project, Meta, Seattle, WA                        Oct 2024 - Present * Developing a framework for generating synthetic training data for LLM training. * Ensuring privacy preservation in the generated techniques by fine-tuning a pre-trained LLM with differential privacy using PyTorch. * Leading the team technically, key providing guidance in technical implementation and design. * Read numerous research papers and implemented them for this use case. AI Engineer Intern, SLB, Houston, TX (Formerly Schlumberger)        Jun 2024 - Present * Implementing enterprise AI solutions by integrating multi-agent AI into the company\\'s infrastructure and developing reusable AI components for enterprise-wide use with langgraph  and azure AI(OpenAI APIs). * Exploring Deep Learning and Knowledge Graphs to improve task routing to Mixture of Expert style agents for LLM inference. * Developed a RAG-based AI-copilot to address documentation-related queries and incorporated agents for real-time API calls and database queries using Mongo VectorDB. Used kubernetes and Docker to containerize apps. * Researched and promoted AI techniques within the organization, including assisting the team in understanding state-of-the-art agentic implementation techniques and evaluating AI monitoring tools. * Avid reader and promoter of latest research in the space within the organisation. \\n...\\nSoftware Developer, SLB, Coimbatore, India (Formerly Schlumberger)        Aug 2021 - Aug 2023 * Spearheaded 6 ServiceNow projects to optimize SLB\\'s digital portfolio, while developing data pipelines, visualizations, and integrations. Developed REST APIs, * Successfully applied Agile methodology, collaborated with stakeholders, and mentored a team of 5 to ensure high-quality results. Research and Development Intern, AppViewX * Contributed to AppViewX\\'s ADC+ product, a comprehensive solution for streamlined load balancer management. Assisted in data ingestion and development of real-time dashboards to visualize load balancer data using Java and spring boot. EDUCATION\\r\\n  University Of Washington, Seattle (GPA: 3.9/4. 0)        2023-2025\\r\\n    Masters in Data Science\\r\\n    Coursework: Applied Statistics, Probability, Data Visualization, Statistical Machine Learning, Explainable AI(XAI)\\r\\n  Amrita Vishwa Vidyapeetham, Kollam, India (GPA: 3.75/4. 0)        2017 - 2021\\r\\n    B. \\n...\\n* Evaluated the performance of various ensemble regression models on a 34-day solar power generation dataset from a solar power plant in India, using Python, Sci-kit learn, pandas, NumPy, and matplotlib. * The research utilized adaptive window sizing (ADWIN) and rolling variance-based training to minimize MAPE error. * The findings were presented at the 12th International Conference on Computing and Networking Technology (ICCNT) and published in  IEEE. \"\n",
      "      }\n",
      "    }\n",
      "    grounding_supports {\n",
      "      segment {\n",
      "        start_index: 72\n",
      "        end_index: 284\n",
      "        text: \"* **AI Engineering and Development:** He has extensive experience in developing and implementing enterprise-level AI solutions, including RAG implementations, GenAI Agentic Frameworks, and LLM prompt engineering.\"\n",
      "      }\n",
      "      grounding_chunk_indices: 0\n",
      "      confidence_scores: 0.887804747\n",
      "    }\n",
      "    grounding_supports {\n",
      "      segment {\n",
      "        start_index: 401\n",
      "        end_index: 542\n",
      "        text: \"His projects demonstrate expertise in building AI copilots,  creating reusable AI libraries, and integrating AI into existing infrastructure.\"\n",
      "      }\n",
      "      grounding_chunk_indices: 0\n",
      "      confidence_scores: 0.629193842\n",
      "    }\n",
      "    grounding_supports {\n",
      "      segment {\n",
      "        start_index: 544\n",
      "        end_index: 738\n",
      "        text: \"* **Software Development:** Abhinav possesses strong software development skills, with experience in building scalable REST APIs, using languages like Python and C#, and frameworks like FastAPI.\"\n",
      "      }\n",
      "      grounding_chunk_indices: 0\n",
      "      confidence_scores: 0.660545707\n",
      "    }\n",
      "    grounding_supports {\n",
      "      segment {\n",
      "        start_index: 822\n",
      "        end_index: 901\n",
      "        text: \"His experience includes working with ServiceNow to optimize digital portfolios.\"\n",
      "      }\n",
      "      grounding_chunk_indices: 0\n",
      "      confidence_scores: 0.947906256\n",
      "    }\n",
      "    grounding_supports {\n",
      "      segment {\n",
      "        start_index: 1729\n",
      "        end_index: 1837\n",
      "        text: \"He is also a strong researcher and actively promotes the latest advancements in AI within his organizations.\"\n",
      "      }\n",
      "      grounding_chunk_indices: 0\n",
      "      confidence_scores: 0.813923657\n",
      "    }\n",
      "  }\n",
      "  avg_logprobs: -0.17379598906545929\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 72\n",
      "  candidates_token_count: 330\n",
      "  total_token_count: 402\n",
      "}\n",
      "model_version: \"gemini-1.5-flash-002\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, SafetySetting, Part, Tool\n",
    "from vertexai.preview.generative_models import grounding\n",
    "\n",
    "\n",
    "def multiturn_generate_content():\n",
    "    vertexai.init(project=\"concise-option-448310-n8\", location=\"us-central1\")\n",
    "    tools = [\n",
    "        Tool.from_retrieval(\n",
    "            retrieval=grounding.Retrieval(\n",
    "                source=grounding.VertexAISearch(datastore=\"projects/concise-option-448310-n8/locations/global/collections/default_collection/dataStores/resume-portfolio_1737284302495\"),\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-1.5-flash-002\",\n",
    "        tools=tools,\n",
    "        system_instruction=[textsi_1]\n",
    "    )\n",
    "    chat = model.start_chat()\n",
    "    print(chat.send_message(\n",
    "        [\"\"\"hi\"\"\"],\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings\n",
    "    ))\n",
    "    print(chat.send_message(\n",
    "        [\"\"\"what is abhinav good at?\"\"\"],\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings\n",
    "    ))\n",
    "\n",
    "textsi_1 = \"\"\"You are an AI bot with context of my resume. You answer questions about me from my resume. You do not use any context outside that and say that you cant answer questions whenever you don't know.\"\"\"\n",
    "\n",
    "generation_config = {\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"temperature\": 0.3,\n",
    "    \"top_p\": 0.95,\n",
    "}\n",
    "\n",
    "safety_settings = [\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "]\n",
    "\n",
    "multiturn_generate_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
